# -*- coding: utf-8 -*-
"""optimizing_learning_rate_colab.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1eECClMU1r-Y9hzPnRw89__jC3nw3C-zD
"""

import numpy as np
import matplotlib.pyplot as plt
# %matplotlib inline

left = 0.0
right = 4.0
samples = np.array([0.0])

def loss(x):
    return 2.0 * (x - 2.0)**2

def loss_gradient(x):
    return 4.0 * (x - 2.0)

def plot(learning_rate):
    global samples
    global left
    global right
    x = np.linspace(left, right)
    fig, ax = plt.subplots(1, 1, figsize=(8, 6))
    ax.grid(True)
    ax.plot(x, loss(x))
    colors = np.full(samples.shape, 0.5)
    ax.scatter(samples, loss(samples))
    last_sample = samples[-1]
    new_sample = last_sample - float(learning_rate) * loss_gradient(last_sample)
    samples = np.append(samples, new_sample)
    left = min(left, new_sample)
    right = max(right, new_sample)

plot(0.15)

